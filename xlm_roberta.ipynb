{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "xlm-roberta.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "nEugRnDsMp0W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from kaggle_datasets import KaggleDatasets\n",
        "import transformers\n",
        "from transformers import TFAutoModel, AutoTokenizer\n",
        "from tqdm.notebook import tqdm\n",
        "from tokenizers import Tokenizer, models, pre_tokenizers, decoders, processors"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Mw8_vvvXMp0s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def regular_encode(texts, tokenizer,maxlen):\n",
        "    enc_di = tokenizer.batch_encode_plus(texts, return_attention_masks=False, return_token_type_ids=False,pad_to_max_length=True,max_length=maxlen)   \n",
        "    return np.array(enc_di['input_ids'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "QcGeUmR-Mp0y",
        "colab_type": "code",
        "colab": {},
        "outputId": "ac273a19-865e-44a2-dde0-bff02bc72be7"
      },
      "source": [
        "# Detect hardware, return appropriate distribution strategy\n",
        "try:\n",
        "    # TPU detection. No parameters necessary if TPU_NAME environment variable is\n",
        "    # set: this is always the case on Kaggle.\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "    print('Running on TPU ', tpu.master())\n",
        "except ValueError:\n",
        "    tpu = None\n",
        "\n",
        "if tpu:\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "else:\n",
        "    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n",
        "    strategy = tf.distribute.get_strategy()\n",
        "\n",
        "print(\"REPLICAS: \", strategy.num_replicas_in_sync)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running on TPU  grpc://10.0.0.2:8470\n",
            "REPLICAS:  8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "1xgTQPYkMp05",
        "colab_type": "code",
        "colab": {
          "referenced_widgets": [
            "ece4b495f5e54e4895f68f3737c6bdc3",
            "edccb2fe46d341619bba388b5a599a2d"
          ]
        },
        "outputId": "0481574c-32d2-498f-9f25-ce2176cc02b9"
      },
      "source": [
        "AUTO = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "# Configuration\n",
        "EPOCHS = 1\n",
        "BATCH_SIZE = 16 * strategy.num_replicas_in_sync\n",
        "MAX_LEN = 512\n",
        "MODEL = 'jplu/tf-xlm-roberta-base'\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=512.0, style=ProgressStyle(description_…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ece4b495f5e54e4895f68f3737c6bdc3"
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=5069051.0, style=ProgressStyle(descript…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "edccb2fe46d341619bba388b5a599a2d"
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "dMuDYplpMp0_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train1 = pd.read_csv(\"/kaggle/input/jigsaw-multilingual-toxic-comment-classification/jigsaw-toxic-comment-train.csv\")\n",
        "train2 = pd.read_csv(\"/kaggle/input/jigsaw-multilingual-toxic-comment-classification/jigsaw-unintended-bias-train.csv\")\n",
        "train2.toxic = train2.toxic.round().astype(int)\n",
        "valid = pd.read_csv(\"/kaggle/input/jigsaw-multilingual-toxic-test-translated/jigsaw_miltilingual_valid_translated.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "RVB-65UjMp1C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.concat([\n",
        "    train1[['comment_text', 'toxic']].query('toxic==0').sample(n=21384, random_state=0),\n",
        "    train1[['comment_text', 'toxic']].query('toxic==1'),\n",
        "    train2[['comment_text', 'toxic']].query('toxic==0').sample(n=112226, random_state=0),\n",
        "    train2[['comment_text', 'toxic']].query('toxic==1'),\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "VkmNkykkMp1H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean(text):\n",
        "    text = text.fillna(\"fillna\").str.lower()\n",
        "    text = text.map(lambda x: re.sub('\\\\n',' ',str(x)))\n",
        "    text = text.map(lambda x: re.sub(\"\\[\\[User.*\",'',str(x)))\n",
        "    text = text.map(lambda x: re.sub(\"\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\",'',str(x)))\n",
        "    text = text.map(lambda x: re.sub(\"\\(http://.*?\\s\\(http://.*\\)\",'',str(x)))\n",
        "    return text\n",
        "\n",
        "valid[\"comment_text\"] = clean(valid[\"translated\"])\n",
        "train[\"comment_text\"] = clean(train[\"comment_text\"])\n",
        "\n",
        "y_valid = valid.toxic.values\n",
        "y_train = train.toxic.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "VR2B_9ySMp1O",
        "colab_type": "code",
        "colab": {},
        "outputId": "cbc00a8f-243b-4321-ef1e-06cb492838bb"
      },
      "source": [
        "%%time \n",
        "\n",
        "x_train = regular_encode(train.comment_text.values, tokenizer, maxlen=MAX_LEN)\n",
        "x_valid = regular_encode(valid.comment_text.values, tokenizer, maxlen=MAX_LEN)\n",
        "n=x_train.shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 3min 55s, sys: 1.71 s, total: 3min 57s\n",
            "Wall time: 3min 57s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "JV3BQ8VAMp1U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = (tf.data.Dataset.from_tensor_slices((x_train, y_train)).repeat().shuffle(2048).batch(BATCH_SIZE).prefetch(AUTO))\n",
        "test_dataset = (tf.data.Dataset.from_tensor_slices((x_valid, y_valid)).batch(BATCH_SIZE))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "i0zEsF4WMp1Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del x_valid,train,train1,train2,y_train,x_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "DHTLDZs5Mp1f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Dropout,Flatten\n",
        "def build_model(transformer, max_len):\n",
        "\n",
        "    input_word_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n",
        "    sequence_output = transformer(input_word_ids)[0]\n",
        "    cls_token = sequence_output[:, :, :]\n",
        "    flat = Flatten()(cls_token)\n",
        "    drop = Dropout(0.1)(flat)\n",
        "    out = Dense(1, activation='sigmoid')(drop)\n",
        "    \n",
        "    model = Model(inputs=input_word_ids, outputs=out)\n",
        "    model.compile(Adam(lr=1e-3), loss='binary_crossentropy', metrics=[tf.keras.metrics.AUC()])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "vs--T6UvMp1k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "with strategy.scope():\n",
        "    transformer_layer = TFAutoModel.from_pretrained(MODEL)\n",
        "    model = build_model(transformer_layer, max_len=MAX_LEN)\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "GwfTI9xyMp1o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_steps = n//BATCH_SIZE\n",
        "train_history = model.fit(train_dataset,steps_per_epoch=n_steps,epochs=EPOCHS,validation_data=test_dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "s3YDLiDpMp1r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pre = model.predict(test_dataset, verbose=1)\n",
        "from sklearn.metrics import roc_auc_score\n",
        "print(roc_auc_score(y_valid,pre))\n",
        "pre2=pre.round()\n",
        "print(roc_auc_score(y_valid,pre2))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}